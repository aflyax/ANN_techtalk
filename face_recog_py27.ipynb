{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nolearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(context='poster', style='dark')\n",
    "\n",
    "# file kfkd.py\n",
    "import os\n",
    "\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from lasagne import layers\n",
    "from lasagne.updates import sgd, nesterov_momentum, rmsprop, adagrad\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "from __future__ import print_function\n",
    "print('loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FTRAIN = 'training.csv'\n",
    "FTEST = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(test=False, cols=None):\n",
    "    \"\"\"Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
    "    Pass a list of *cols* if you're only interested in a subset of the\n",
    "    target columns.\n",
    "    \"\"\"\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = pd.read_csv(os.path.expanduser(fname))  # load pandas dataframe\n",
    "\n",
    "    # The Image column has pixel values separated by space; convert\n",
    "    # the values to numpy arrays:\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    if cols:  # get a subset of columns\n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    print(df.count())  # prints the number of values for each column\n",
    "    df = df.dropna()  # drop all rows that have missing values in them\n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255.  # scale pixel values to [0, 1]\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    if not test:  # only FTRAIN has any target columns\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  # scale target coordinates to [-1, 1]\n",
    "        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y\n",
    "    \n",
    "    \n",
    "def plot_training_history(net0, yscale='log'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    train_loss = np.array([i[\"train_loss\"] for i in net0.train_history_])\n",
    "    valid_loss = np.array([i[\"valid_loss\"] for i in net0.train_history_])\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    fig = plt.yscale(yscale)\n",
    "        \n",
    "    fig = plt.plot(train_loss, '-r', label=\"train\",)\n",
    "    fig = plt.plot(valid_loss, label=\"valid\")\n",
    "    fig = plt.grid()\n",
    "    fig =  plt.legend()\n",
    "    fig = plt.xlabel(\"epoch\")\n",
    "    fig = plt.ylabel(\"loss\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_sample(x, y, axis, dot_color = 'magenta'):\n",
    "    img = x.reshape(96, 96)\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    axis.scatter(y[0::2] * 48 + 48, y[1::2] * 48 + 48, marker='o', s=15, color=dot_color)\n",
    "    \n",
    "    \n",
    "def plot_faces(X_test, y_pred, dot_color = 'magenta'):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.subplots_adjust(\n",
    "        left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(16):\n",
    "        ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "        plot_sample(X_test[i], y_pred[i], ax, dot_color = dot_color)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# train dataset\n",
    "\n",
    "def plot_train_comparison(net):\n",
    "    y_pred_1 = net.predict(X)\n",
    "\n",
    "    print('ground truth:')\n",
    "    plot_faces(X, y, dot_color='blue')\n",
    "\n",
    "    print('\\nprediction:')\n",
    "    plot_faces(X, y_pred_1)\n",
    "    \n",
    "    \n",
    "def plot_test_pred(net):\n",
    "    y_pred_test = net.predict(X_test)\n",
    "    plot_faces(X_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('this will take a bit')\n",
    "X, y = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple ANN with one layer\n",
    "\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "net0 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer)\n",
    "        ,('hidden', layers.DenseLayer)\n",
    "        ,('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 9216),  # 96x96 input pixels per batch\n",
    "    hidden_num_units=100,  # number of units in hidden layer\n",
    "    output_nonlinearity=None,  # output layer uses identity function\n",
    "    output_num_units=30,  # 30 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=sgd,\n",
    "    update_learning_rate=0.01,\n",
    "\n",
    "    regression=True,  # flag to indicate we're dealing with regression problem\n",
    "    max_epochs=50,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "net0.fit(X, y)\n",
    "plot_training_history(net0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# change update to nesterov_momentum\n",
    "# it's named after a Russian guy; must be good\n",
    "\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer)\n",
    "        ,('hidden', layers.DenseLayer)\n",
    "        ,('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 9216),  # 96x96 input pixels per batch\n",
    "    hidden_num_units=100,  # number of units in hidden layer\n",
    "    output_nonlinearity=None,  # output layer uses identity function\n",
    "    output_num_units=30,  # 30 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.01,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=True,  # flag to indicate we're dealing with regression problem\n",
    "    max_epochs=50,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "net1.fit(X, y)\n",
    "plot_training_history(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_train_comparison(net0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test dataset\n",
    "\n",
    "X_test, _ = load(test=True)\n",
    "    \n",
    "plot_test_pred(net0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_test_pred(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add a layer\n",
    "# a few more layers, and it can beat AlphaGo\n",
    "\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "net3 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer)\n",
    "        ,('hidden1', layers.DenseLayer)\n",
    "        ,('hidden2', layers.DenseLayer)        \n",
    "        ,('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 9216),  # 96x96 input pixels per batch\n",
    "    hidden1_num_units=100,  # number of units in hidden layer\n",
    "    hidden2_num_units=100,  # number of units in hidden layer\n",
    "    output_nonlinearity=None,  # output layer uses identity function\n",
    "    output_num_units=30,  # 30 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.01,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=True,  # flag to indicate we're dealing with regression problem\n",
    "    max_epochs=50,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "net3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_test_pred(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_training_history(net1)\n",
    "plot_training_history(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add dropout layers\n",
    "\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "net4 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer)\n",
    "        , ('dropout_0', layers.DropoutLayer)\n",
    "        ,('hidden1', layers.DenseLayer)\n",
    "        , ('dropout_1', layers.DropoutLayer)\n",
    "        ,('hidden2', layers.DenseLayer)   \n",
    "        ,('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 9216),  # 96x96 input pixels per batch\n",
    "    hidden1_num_units=100,  # number of units in hidden layer\n",
    "    hidden2_num_units=100,  # number of units in hidden layer\n",
    "    dropout_0_p=0.5, # probability for dropout for dropout_0\n",
    "    dropout_1_p=0.5,\n",
    "    output_nonlinearity=None,  # output layer uses identity function\n",
    "    output_num_units=30,  # 30 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.01,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=True,  # flag to indicate we're dealing with regression problem\n",
    "    max_epochs=50,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "net4.fit(X, y)\n",
    "\n",
    "plot_training_history(net4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# increase learning rate\n",
    "\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "net5 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer)\n",
    "        , ('dropout_0', layers.DropoutLayer)\n",
    "        ,('hidden1', layers.DenseLayer)\n",
    "        , ('dropout_1', layers.DropoutLayer)\n",
    "        ,('hidden2', layers.DenseLayer)   \n",
    "        ,('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 9216),  # 96x96 input pixels per batch\n",
    "    hidden1_num_units=100,  # number of units in hidden layer\n",
    "    hidden2_num_units=100,  # number of units in hidden layer\n",
    "    dropout_0_p=0.5,\n",
    "    dropout_1_p=0.5,\n",
    "    output_nonlinearity=None,  # output layer uses identity function\n",
    "    output_num_units=30,  # 30 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.05,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=True,  # flag to indicate we're dealing with regression problem\n",
    "    max_epochs=50,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "net5.fit(X, y)\n",
    "\n",
    "plot_training_history(net5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try rmsprop activation\n",
    "\n",
    "import theano\n",
    "\n",
    "from lasagne.nonlinearities import sigmoid, rectify, very_leaky_rectify\n",
    "# scaled_tanh = ScaledTanH()\n",
    "\n",
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "\n",
    "        \n",
    "\n",
    "net6 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer)\n",
    "        , ('dropout_0', layers.DropoutLayer)\n",
    "        ,('hidden1', layers.DenseLayer)\n",
    "        , ('dropout_1', layers.DropoutLayer)\n",
    "        ,('hidden2', layers.DenseLayer)   \n",
    "        ,('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 9216),  # 96x96 input pixels per batch\n",
    "    hidden1_num_units=100,  # number of units in hidden layer\n",
    "    hidden1_nonlinearity=rectify, # can also try sigmoid\n",
    "    hidden2_num_units=100,  # number of units in hidden layer\n",
    "    hidden2_nonlinearity=rectify,\n",
    "    dropout_0_p=0.50,\n",
    "    dropout_1_p=0.50,\n",
    "    output_nonlinearity=None,  # output layer uses identity function\n",
    "    output_num_units=30,  # 30 target values\n",
    "    \n",
    "    \n",
    "    # optimization method:\n",
    "    update=rmsprop,\n",
    "#     update_learning_rate=0.005,\n",
    "#     update_momentum=0.85,\n",
    "    update_learning_rate=theano.shared(float32(0.05)),\n",
    "#     update_momentum=theano.shared(float32(0.9)),\n",
    "\n",
    "    \n",
    "# adjust learning rate: uncomment if interested:    \n",
    "#     on_epoch_finished=[\n",
    "#         AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "#         AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "#         ],\n",
    "    \n",
    "    \n",
    "    \n",
    "    regression=True,  # flag to indicate we're dealing with regression problem\n",
    "    max_epochs=50,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "net6.fit(X, y)\n",
    "\n",
    "plot_training_history(net6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change dropout rates a bit\n",
    "\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "net7 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer)\n",
    "        , ('dropout_0', layers.DropoutLayer)\n",
    "        ,('hidden1', layers.DenseLayer)\n",
    "        , ('dropout_1', layers.DropoutLayer)\n",
    "        ,('hidden2', layers.DenseLayer)   \n",
    "        ,('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 9216),  # 96x96 input pixels per batch\n",
    "    hidden1_num_units=100,  # number of units in hidden layer\n",
    "    hidden2_num_units=100,  # number of units in hidden layer\n",
    "    dropout_0_p=0.75,\n",
    "    dropout_1_p=0.10,\n",
    "    output_nonlinearity=None,  # output layer uses identity function\n",
    "    output_num_units=30,  # 30 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update_learning_rate=theano.shared(float32(0.05)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "\n",
    "    \n",
    "# adjust learning rate:\n",
    "    on_epoch_finished=[\n",
    "        AdjustVariable('update_learning_rate', start=0.05, stop=0.0001),\n",
    "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        ],\n",
    "    \n",
    "\n",
    "    regression=True,  # flag to indicate we're dealing with regression problem\n",
    "    max_epochs=50,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "net7.fit(X, y)\n",
    "\n",
    "plot_training_history(net7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try your own\n",
    "# http://lasagne.readthedocs.org/en/latest/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
